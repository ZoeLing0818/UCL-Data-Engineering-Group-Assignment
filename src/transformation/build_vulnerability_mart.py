#!/usr/bin/env python3
"""Join NVD, CISA KEV, and EPSS feeds into a curated vulnerability mart."""

from __future__ import annotations

import argparse
import csv
import json
from pathlib import Path
from typing import Any


REPO_ROOT = Path(__file__).resolve().parents[2]
DEFAULT_DATA_DIR = REPO_ROOT / "data"


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Build a curated vulnerability mart from raw NVD, CISA KEV, and EPSS data."
    )
    parser.add_argument(
        "--data-dir",
        default=str(DEFAULT_DATA_DIR),
        help="Base data directory (default: <repo>/data).",
    )
    return parser.parse_args()


def load_json(path: Path) -> dict[str, Any]:
    with path.open("r", encoding="utf-8") as handle:
        return json.load(handle)


def extract_cwe(cve_obj: dict[str, Any]) -> str:
    for weakness in cve_obj.get("weaknesses", []):
        for description in weakness.get("description", []):
            value = (description.get("value") or "").strip()
            if value.startswith("CWE-"):
                return value
    return ""


def extract_cvss(metrics: dict[str, Any]) -> tuple[str, float | None, str]:
    for key in ("cvssMetricV31", "cvssMetricV30", "cvssMetricV2"):
        items = metrics.get(key, [])
        if not items:
            continue
        primary = items[0]
        cvss_data = primary.get("cvssData", {})
        version = str(cvss_data.get("version", ""))
        score = cvss_data.get("baseScore")
        severity = cvss_data.get("baseSeverity") or primary.get("baseSeverity", "")
        return version, float(score) if score is not None else None, severity
    return "", None, ""


def extract_vendor_product(cve_obj: dict[str, Any]) -> tuple[str, str]:
    for configuration in cve_obj.get("configurations", []):
        for node in configuration.get("nodes", []):
            for match in node.get("cpeMatch", []):
                criteria = match.get("criteria", "")
                parts = criteria.split(":")
                if len(parts) >= 5 and parts[0] == "cpe" and parts[1] == "2.3":
                    return parts[3], parts[4]
    return "", ""


def flatten_nvd(payload: dict[str, Any]) -> list[dict[str, Any]]:
    rows: list[dict[str, Any]] = []
    for item in payload.get("vulnerabilities", []):
        cve = item.get("cve", {})
        metrics = cve.get("metrics", {})
        cvss_version, cvss_score, cvss_severity = extract_cvss(metrics)
        vendor, product = extract_vendor_product(cve)
        rows.append(
            {
                "cve_id": cve.get("id", ""),
                "published": cve.get("published", ""),
                "last_modified": cve.get("lastModified", ""),
                "vuln_status": cve.get("vulnStatus", ""),
                "cvss_version": cvss_version,
                "cvss_base_score": cvss_score,
                "cvss_severity": cvss_severity,
                "cwe_id": extract_cwe(cve),
                "vendor": vendor,
                "product": product,
            }
        )
    return rows


def build_kev_index(payload: dict[str, Any]) -> dict[str, dict[str, Any]]:
    index: dict[str, dict[str, Any]] = {}
    for item in payload.get("vulnerabilities", []):
        cve_id = item.get("cveID", "")
        if cve_id:
            index[cve_id] = item
    return index


def build_epss_index(payload: dict[str, Any]) -> dict[str, dict[str, Any]]:
    index: dict[str, dict[str, Any]] = {}
    for item in payload.get("data", []):
        cve_id = item.get("cve", "")
        if cve_id:
            index[cve_id] = item
    return index


def priority_bucket(cvss_score: float | None, in_kev: bool, epss_score: float | None) -> str:
    if in_kev:
        return "critical"
    if epss_score is not None and epss_score >= 0.9:
        return "critical"
    if cvss_score is not None and cvss_score >= 9.0:
        return "critical"
    if epss_score is not None and epss_score >= 0.7:
        return "high"
    if cvss_score is not None and cvss_score >= 7.0:
        return "high"
    if epss_score is not None and epss_score >= 0.3:
        return "medium"
    if cvss_score is not None and cvss_score >= 4.0:
        return "medium"
    return "low"


def merge_rows(
    nvd_rows: list[dict[str, Any]],
    kev_index: dict[str, dict[str, Any]],
    epss_index: dict[str, dict[str, Any]],
) -> list[dict[str, Any]]:
    rows: list[dict[str, Any]] = []
    for row in nvd_rows:
        cve_id = row["cve_id"]
        kev = kev_index.get(cve_id, {})
        epss = epss_index.get(cve_id, {})

        epss_score = float(epss["epss"]) if epss.get("epss") not in (None, "") else None
        epss_percentile = (
            float(epss["percentile"]) if epss.get("percentile") not in (None, "") else None
        )
        in_kev = bool(kev)

        rows.append(
            {
                **row,
                "in_kev": in_kev,
                "kev_date_added": kev.get("dateAdded", ""),
                "kev_due_date": kev.get("dueDate", ""),
                "kev_ransomware_use": kev.get("knownRansomwareCampaignUse", ""),
                "epss_score": epss_score,
                "epss_percentile": epss_percentile,
                "priority_bucket": priority_bucket(row["cvss_base_score"], in_kev, epss_score),
            }
        )
    return rows


def write_jsonl(path: Path, rows: list[dict[str, Any]]) -> None:
    with path.open("w", encoding="utf-8") as handle:
        for row in rows:
            handle.write(json.dumps(row, ensure_ascii=False) + "\n")


def write_csv(path: Path, rows: list[dict[str, Any]]) -> None:
    if not rows:
        path.write_text("", encoding="utf-8")
        return
    with path.open("w", encoding="utf-8", newline="") as handle:
        writer = csv.DictWriter(handle, fieldnames=list(rows[0].keys()))
        writer.writeheader()
        writer.writerows(rows)


def write_parquet_if_available(path: Path, rows: list[dict[str, Any]]) -> bool:
    try:
        import pyarrow as pa  # type: ignore
        import pyarrow.parquet as pq  # type: ignore
    except Exception:
        return False

    table = pa.Table.from_pylist(rows)
    pq.write_table(table, path)
    return True


def main() -> int:
    args = parse_args()
    data_dir = Path(args.data_dir)

    nvd_path = data_dir / "raw" / "nvd" / "nvdcve-2.0-2026.json"
    kev_path = data_dir / "raw" / "cisa_kev" / "cisa_kev_catalog.json"
    epss_path = data_dir / "raw" / "epss" / "epss_scores.json"

    nvd = load_json(nvd_path)
    kev = load_json(kev_path)
    epss = load_json(epss_path)

    nvd_rows = flatten_nvd(nvd)
    merged_rows = merge_rows(nvd_rows, build_kev_index(kev), build_epss_index(epss))

    curated_dir = data_dir / "curated" / "vulnerability_priority"
    curated_dir.mkdir(parents=True, exist_ok=True)

    jsonl_path = curated_dir / "vulnerability_priority_latest.jsonl"
    csv_path = curated_dir / "vulnerability_priority_latest.csv"
    parquet_path = curated_dir / "vulnerability_priority_latest.parquet"

    write_jsonl(jsonl_path, merged_rows)
    write_csv(csv_path, merged_rows)
    wrote_parquet = write_parquet_if_available(parquet_path, merged_rows)

    print(f"Built curated rows: {len(merged_rows)}")
    print(f"JSONL: {jsonl_path}")
    print(f"CSV: {csv_path}")
    if wrote_parquet:
        print(f"Parquet: {parquet_path}")
    else:
        print("Parquet skipped: pyarrow not installed")

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
